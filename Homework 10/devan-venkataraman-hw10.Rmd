---
title: "CSCI E-63C Problem Set 10"
output:
  html_document:
    toc: true
---

```{r setup, include=FALSE}
library(randomForest)
library(MASS)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
```

# Sub-problem 1 (15 points): effect of sample size

Generate training datasets with `nObs=25`, `100` and `500` observations such that two variables are associated with the outcome as parameterized above and three are not associated and average difference between the two classes is the same as above (i.e. in the notation from the above code `nClassVars=2`, `nNoiseVars=3` and `deltaClass=1`).  Obtain random forest, LDA and KNN test error rates on a (for greater stability of the results, much larger, say, with 10K observations) test dataset simulated from the same model.  Describe the differences between different methods and across the sample sizes used here.

``` {r subproblem1pt1}
# Generate the dataset, repeat 3 times
for (nObs in c(25, 100, 500)) {
  # How many predictors are associated with outcome:
  nClassVars <- 2
  # How many predictors are not:
  nNoiseVars <- 3
  # To modulate average difference between two classes' predictor values:
  deltaClass <- 1
  # Simulate training and test datasets with an interaction 
  # between attribute levels associated with the outcome:
  xyzTrain <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
  xyzTest <- matrix(rnorm(10000*(nClassVars+nNoiseVars)),nrow=10000,ncol=nClassVars+nNoiseVars)
  classTrain <- 1
  classTest <- 1
  for ( iTmp in 1:nClassVars ) {
    deltaTrain <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
    xyzTrain[,iTmp] <- xyzTrain[,iTmp] + deltaTrain
    classTrain <- classTrain * deltaTrain
    deltaTest <- sample(deltaClass*c(-1,1),10000,replace=TRUE)
    xyzTest[,iTmp] <- xyzTest[,iTmp] + deltaTest
    classTest <- classTest * deltaTest
  }
  classTrain <- factor(classTrain > 0)
  classTrain
  
  xyzTrain
  
  print(paste("Number of observations: ", nObs))
  rfRes <- randomForest(xyzTrain,classTrain)
  rfTmpTbl <- table(classTest,predict(rfRes,newdata=xyzTest))
  
  ldaRes <- lda(xyzTrain,classTrain)
  ldaTmpTbl <- table(classTest,predict(ldaRes,newdata=xyzTest)$class)
  
  dfTmp <- NULL
  for ( kTmp in seq(1,nObs/2,length.out = 20) ) {
    knnRes <- knn(xyzTrain,xyzTest,classTrain,k=kTmp)
    tmpTbl <- table(classTest,knnRes)
    dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
  }
  print(ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate"))
}
```

**Above, we compare results from random forest, LDA, and KNN classification techniques across simulated datasets of varying sizes. We see better results consistently from the random forest technique than LDA, as expected given the setup of the simulated dataset. For a small dataset (25 observations), we find that KNN results in the lowest error. However across datasets, random forest emerges as the method with lowest error (when compared to most values of K for KNN). We see consistent improvement with the random forest technique as the dataset grows in size, but not with the LDA. This further suggests that random forest is a more fitting method of classification for the data, whereas LDA is unable to improve.**


# Sub-problem 2 (15 points): effect of signal magnitude

For training datasets with `nObs=100` and `500` observations simulate data as shown above with average differences between the two classes that are same as above, half of that and twice that (i.e. `deltaClass=0.5`, `1` and `2`).  Obtain and plot test error rates of random forest, LDA and KNN for each of the six (two samples sizes times three signal magnitudes) combinations of sample size and signal strengths.  As before use large test dataset (e.g. 10K observations or so) for greater stability of the results.  Describe the most pronounced differences across error rates for those datasets: does the increase in the number of observations impact the error rate of the models?  Does change in the magnitude of signal impact their performance?  Are different classifier approaches impacted in a similar way?

``` {r subproblem2pt1}
for (deltaClass in c(0.5, 1, 2)) {
    # Generate the dataset, repeat 3 times
  for (nObs in c(100, 500)) {
    # How many predictors are associated with outcome:
    nClassVars <- 2
    # How many predictors are not:
    nNoiseVars <- 3
    # Simulate training and test datasets with an interaction 
    # between attribute levels associated with the outcome:
    xyzTrain <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
    xyzTest <- matrix(rnorm(10000*(nClassVars+nNoiseVars)),nrow=10000,ncol=nClassVars+nNoiseVars)
    classTrain <- 1
    classTest <- 1
    for ( iTmp in 1:nClassVars ) {
      deltaTrain <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
      xyzTrain[,iTmp] <- xyzTrain[,iTmp] + deltaTrain
      classTrain <- classTrain * deltaTrain
      deltaTest <- sample(deltaClass*c(-1,1),10000,replace=TRUE)
      xyzTest[,iTmp] <- xyzTest[,iTmp] + deltaTest
      classTest <- classTest * deltaTest
    }
    classTrain <- factor(classTrain > 0)

    print(paste("Number of observations: ", nObs))
    rfRes <- randomForest(xyzTrain,classTrain)
    rfTmpTbl <- table(classTest,predict(rfRes,newdata=xyzTest))
    rferror <- (rfTmpTbl[2,1]+rfTmpTbl[1,2])/sum(rfTmpTbl)
    
    ldaRes <- lda(xyzTrain,classTrain)
    ldaTmpTbl <- table(classTest,predict(ldaRes,newdata=xyzTest)$class)
    ldaerror <- (ldaTmpTbl[2,1]+ldaTmpTbl[1,2])/sum(ldaTmpTbl)
    
    dfTmp <- NULL
    for ( kTmp in seq(1,nObs/2,length.out = 20) ) {
      knnRes <- knn(xyzTrain,xyzTest,classTrain,k=kTmp)
      tmpTbl <- table(classTest,knnRes)
      dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
    }
    print(ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate"))
  }
}
```

**Once again, we see random forest drastically outperforming LDA across all datasets and differences in predictor variables. The increase in difference in predictor variables results in widely improved random forest and knn models, from an error ~0.47 to ~0.05. Such improvement across increasingly different variables shows that the models are able to improve based on the pattern of the dataset. Similar to the previous experiment, LDA is unable to improve.**

# Sub-problem 3 (15 points): varying counts of predictors

For all possible pairwise combinations of the numbers of variables associated with outcome (`nClassVars=2` and `5`) and those not associated with the outcome (`nNoiseVars=1`, `3` and `10`) -- six pairwise combinations in total -- obtain and present graphically test errors from random forest, LDA and KNN.  Choose signal magnitude (`deltaClass`) and training data sample size so that this simulation yields non-trivial results -- noticeable variability in the error rates across those six pairwise combinations of attribute counts.  Describe the results: what is the impact of the increase of the number of attributes associated with the outcome on the classifier performance?  What about the number of attributes not associated with outcome - does it affect classifier error rate?  Are different classifier methods affected by these simulation parameters in a similar way?

``` {r subproblem3pt1}
for (nClassVars in c(2,5)) {
    # Generate the dataset, repeat 3 times
  for (nNoiseVars in c(1, 3, 10)) {
    # How many predictors are associated with outcome:
    deltaClass <- 1
    nObs <- 500
    # Simulate training and test datasets with an interaction 
    # between attribute levels associated with the outcome:
    xyzTrain <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
    xyzTest <- matrix(rnorm(10000*(nClassVars+nNoiseVars)),nrow=10000,ncol=nClassVars+nNoiseVars)
    classTrain <- 1
    classTest <- 1
    for ( iTmp in 1:nClassVars ) {
      deltaTrain <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
      xyzTrain[,iTmp] <- xyzTrain[,iTmp] + deltaTrain
      classTrain <- classTrain * deltaTrain
      deltaTest <- sample(deltaClass*c(-1,1),10000,replace=TRUE)
      xyzTest[,iTmp] <- xyzTest[,iTmp] + deltaTest
      classTest <- classTest * deltaTest
    }
    classTrain <- factor(classTrain > 0)

    print(paste("Number of predictor variables: ", nClassVars))
    print(paste("Number of noise variables: ", nNoiseVars))
    rfRes <- randomForest(xyzTrain,classTrain)
    rfTmpTbl <- table(classTest,predict(rfRes,newdata=xyzTest))
    rferror <- (rfTmpTbl[2,1]+rfTmpTbl[1,2])/sum(rfTmpTbl)
    
    ldaRes <- lda(xyzTrain,classTrain)
    ldaTmpTbl <- table(classTest,predict(ldaRes,newdata=xyzTest)$class)
    ldaerror <- (ldaTmpTbl[2,1]+ldaTmpTbl[1,2])/sum(ldaTmpTbl)
    
    dfTmp <- NULL
    for ( kTmp in seq(1,nObs/2,length.out = 20) ) {
      knnRes <- knn(xyzTrain,xyzTest,classTrain,k=kTmp)
      tmpTbl <- table(classTest,knnRes)
      dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
    }
    print(ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate"))
  }
}
```

**There is a stark contrast when we begin to adjust the number of legitimate predictor and noise variables in the dataset. First, with an increase in nClassVars (meaningful predictor variables) from 2 to 5, the effectiveness of our random forest model goes way down (much higher error). This makes sense, as there are more variables contributing to the outcome, and thus it is more difficult to properly classify. For 2 of the 3 datasets with 5 contributing predictor variables, we see LDA actually outperform random forest. As the number of noise variables increase, we see slight increases in error in random forest and larger increases in error in LDA. Random forest is better able to ignore these noise variables while LDA is thrown off further.**

# Sub-problem 4: (15 points): effect of `mtry`

Parameter `mtry` in the call to `randomForest` defines the number of predictors randomly chosen to be evaluated for their association with the outcome at each split (please see help page for `randomForest` for more details).  By default for classification problem it is set as a square root of the number of predictors in the dataset.  Here we will evaluate the impact of using different values of `mtry` on the error rate by random forest.

For `nObs=5000`, `deltaClass=2`, `nClassVars=3` and `nNoiseVars=20` generate data using the above approach, run `randomForest` on it with `mtry=2`, `5` and `10` and obtain corresponding test error for these three models.  Describe the impact of using different values of `mtry` on the test error rate by random forest and compare it to that by LDA/KNN.

``` {r subproblem4pt1}
# Generate the dataset, repeat 3 times
for (myMtry in c(2, 5, 10)) {
  # How many predictors are associated with outcome:
  nClassVars <- 3
  # How many predictors are not:
  nNoiseVars <- 20
  # To modulate average difference between two classes' predictor values:
  deltaClass <- 2
  nObs <- 5000
  # Simulate training and test datasets with an interaction 
  # between attribute levels associated with the outcome:
  xyzTrain <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
  xyzTest <- matrix(rnorm(10000*(nClassVars+nNoiseVars)),nrow=10000,ncol=nClassVars+nNoiseVars)
  classTrain <- 1
  classTest <- 1
  for ( iTmp in 1:nClassVars ) {
    deltaTrain <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
    xyzTrain[,iTmp] <- xyzTrain[,iTmp] + deltaTrain
    classTrain <- classTrain * deltaTrain
    deltaTest <- sample(deltaClass*c(-1,1),10000,replace=TRUE)
    xyzTest[,iTmp] <- xyzTest[,iTmp] + deltaTest
    classTest <- classTest * deltaTest
  }
  classTrain <- factor(classTrain > 0)
  
  rfRes <- randomForest(xyzTrain,classTrain, mtry = myMtry)
  rfTmpTbl <- table(classTest,predict(rfRes,newdata=xyzTest))
  
  ldaRes <- lda(xyzTrain,classTrain)
  ldaTmpTbl <- table(classTest,predict(ldaRes,newdata=xyzTest)$class)
  
  dfTmp <- NULL
  for ( kTmp in seq(1,100,length.out = 20) ) {
    knnRes <- knn(xyzTrain,xyzTest,classTrain,k=kTmp)
    tmpTbl <- table(classTest,knnRes)
    dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
  }
  print(ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate"))
}
```

**As the number of variables randomly sampled from at each split increases, the error of the random forest model goes down. This makes sense, as it gives us greater ability to explain outcome. However, each of these random forest models are outperformed by corresponding KNN models. This is due to the high number of noise variables (20) that cloud the random forest's abilities to classify effectively. KNN is largely unaffected by these noise variables.**