lmTmp <- lm(FundData$contrib~.,inpDat[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((inpDat[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:nBoot ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(inpDat),nrow(inpDat),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(FundData$contrib~.,inpDat[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((inpDat[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((inpDat[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=inpDat[-tmpBootIdx,1:iTmp]))^2))
}
}
# return results (bootstrap training errors, bootstrap test errors, and training errors
# claculated on the full dataset) as different slots in the list:
list(bootTrain=errTrain,bootTest=errTest,allTrain=allTrainErr)
}
# wrapper for plotting:
# takes the result returned by our bootstrapping functions. colMeans() will calculate the *average*
# train and test errors (averaged across rows, i.e. across multiple bootstrap iterations):
plotBootRegrErrRes <- function(inpRes,inpPchClr=c(1,2,4),...) {
matplot(1:length(inpRes$allTrain),cbind(inpRes$allTrain,
colMeans(inpRes$bootTrain),
colMeans(inpRes$bootTest)
),
pch=inpPchClr,col=inpPchClr,lty=1,type="b",xlab="Number of predictors",ylab="Regression error",...)
legend("topright",c("train all","train boot","test boot"),
col=inpPchClr,text.col=inpPchClr,pch=inpPchClr,lty=1)
}
bootErrRes <- bootTrainTestErrOneAllVars(FundData,5)
plotBootRegrErrRes(bootErrRes,main="3470 observations")
abline(h=sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2)),lty=2)
dim(errTrain)
errTrain <- matrix(NA,nrow=nBoot,ncol=ncol(inpDat)-1)
errTrain <- matrix(NA,nrow=nBoot,ncol=ncol(inpDat)-1)
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(Y~.,inpDat[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((inpDat[,"Y"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:nBoot ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(inpDat),nrow(inpDat),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(Y~.,inpDat[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((inpDat[tmpBootIdx,"Y"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((inpDat[-tmpBootIdx,"Y"]-
predict(lmTmpBoot,newdata=inpDat[-tmpBootIdx,1:iTmp]))^2))
}
}
dim(errTest)
dim(errTrain)
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((inpDat[,"Y"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:nBoot ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(inpDat),nrow(inpDat),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(Y~.,inpDat[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((inpDat[tmpBootIdx,"Y"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((inpDat[-tmpBootIdx,"Y"]-
predict(lmTmpBoot,newdata=inpDat[-tmpBootIdx,1:iTmp]))^2))
}
}
head(FundData)
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,2:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((inpDat[,"Y"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:nBoot ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(inpDat),nrow(inpDat),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(Y~.,inpDat[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((inpDat[tmpBootIdx,"Y"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((inpDat[-tmpBootIdx,"Y"]-
predict(lmTmpBoot,newdata=inpDat[-tmpBootIdx,1:iTmp]))^2))
}
}
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((inpDat[,"Y"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:nBoot ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(inpDat),nrow(inpDat),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(Y~.,inpDat[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((inpDat[tmpBootIdx,"Y"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((inpDat[-tmpBootIdx,"Y"]-
predict(lmTmpBoot,newdata=inpDat[-tmpBootIdx,1:iTmp]))^2))
}
}
# 50 bootstrap iterations
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:50 ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(FundData),nrow(FundData),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(FundData$contrib~.,FundData[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((FundData[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((FundData[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=FundData[-tmpBootIdx,1:iTmp]))^2))
}
}
# return results (bootstrap training errors, bootstrap test errors, and training errors
# claculated on the full dataset) as different slots in the list:
list(bootTrain=errTrain,bootTest=errTest,allTrain=allTrainErr)
# 50 bootstrap iterations
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:50 ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(FundData),nrow(FundData),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(FundData$contrib~.,FundData[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((FundData[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((FundData[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=FundData[-tmpBootIdx,1:iTmp]))^2))
}
}
# return results (bootstrap training errors, bootstrap test errors, and training errors
# claculated on the full dataset) as different slots in the list:
MyInpRes <- list(bootTrain=errTrain,bootTest=errTest,allTrain=allTrainErr)
plotBootRegrErrRes <- function(inpRes,inpPchClr=c(1,2,4),...) {
matplot(1:length(inpRes$allTrain),cbind(inpRes$allTrain,
colMeans(inpRes$bootTrain),
colMeans(inpRes$bootTest)
),
pch=inpPchClr,col=inpPchClr,lty=1,type="b",xlab="Number of predictors",ylab="Regression error",...)
legend("topright",c("train all","train boot","test boot"),
col=inpPchClr,text.col=inpPchClr,pch=inpPchClr,lty=1)
}
plotBootRegrErrRes(bootErrRes,main="3470 observations",ylim=c(min(colMeans(bootErrRes$bootTrain)),sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2))))
abline(h=sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2)),lty=2)
# 50 bootstrap iterations
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:50 ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(FundData),nrow(FundData),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(FundData$contrib~.,FundData[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((FundData[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((FundData[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=FundData[-tmpBootIdx,1:iTmp]))^2))
}
}
# return results (bootstrap training errors, bootstrap test errors, and training errors
# claculated on the full dataset) as different slots in the list:
MyInpRes <- list(bootTrain=errTrain,bootTest=errTest,allTrain=allTrainErr)
plotBootRegrErrRes <- function(inpRes,inpPchClr=c(1,2,4),...) {
matplot(1:length(inpRes$allTrain),cbind(inpRes$allTrain,
colMeans(inpRes$bootTrain),
colMeans(inpRes$bootTest)
),
pch=inpPchClr,col=inpPchClr,lty=1,type="b",xlab="Number of predictors",ylab="Regression error",...)
legend("topright",c("train all","train boot","test boot"),
col=inpPchClr,text.col=inpPchClr,pch=inpPchClr,lty=1)
}
plotBootRegrErrRes(bootErrRes,main="3470 observations")
abline(h=sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2)),lty=2)
head(FundData)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove stated variables
FundData <- fundraising[,c(-13, -14)]
head(FundData)
# Log transform data
FundData <- log(FundData + 1)
CorDat <- as.data.frame(cor(FundData))
CorDat <- CorDat[1,]
CorDat <- sort(abs(CorDat), decreasing=TRUE)
FundData <- FundData[,colnames(CorDat)]
FundData
x2Tmp
x2Tmp <- NULL
tmpCnms <- NULL
# for each original variable:
for ( iTmp in 2:ncol(FundData) ) {
# multiply it by itself and all other terms,
# excluding already generated pairwise combinations:
for ( jTmp in iTmp:ncol(FundData) ) {
x2Tmp <- cbind(x2Tmp,FundData[,iTmp]*FundData[,jTmp])
# maintain vector of column names for quadratic
# terms along the way:
tmpCnms <- c(tmpCnms,paste0("X",iTmp,"X",jTmp))
}
}
colnames(x2Tmp) <- tmpCnms
x2Tmp
FundData <- data.frame(FundData, x2Tmp)
head(FundData)
df2plot <- NULL
for ( iTmp in 2:ncol(FundData) ) {
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
errTmp <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
df2plot <- rbind(df2plot,data.frame(nvars=iTmp-1,err=errTmp))
}
plot(df2plot,xlab="Number of variables",ylab="Regression error",main=paste(nrow(FundData),"observations"),ylim=c(min(df2plot[,"err"]),sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2))))
abline(h=sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2)),lty=2)
tmpBootIdx
summary(lmTmpBoot)
dim(tmpBootIdx)
head(tmpBootIdx)
mode(tmpBootIdx)
class(tmpBootIdx)
length(tmpBootIdx)
summary(lmTmp)
df2plot <- NULL
for ( iTmp in 2:ncol(FundData) ) {
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
errTmp <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
df2plot <- rbind(df2plot,data.frame(nvars=iTmp-1,err=errTmp))
}
plot(df2plot,xlab="Number of variables",ylab="Regression error",main=paste(nrow(FundData),"observations"),ylim=c(min(df2plot[,"err"]),sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2))))
abline(h=sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2)),lty=2)
# 50 bootstrap iterations
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:50 ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(FundData),nrow(FundData),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(FundData$contrib~.,FundData[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((FundData[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((FundData[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=FundData[-tmpBootIdx,1:iTmp]))^2))
}
}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove stated variables
FundData <- fundraising[,c(-13, -14)]
head(FundData)
# Log transform data
FundData <- log(FundData + 1)
# Save a copy to reference predictions later
FundDataCopy <- FundData
CorDat <- as.data.frame(cor(FundData))
CorDat <- CorDat[1,]
CorDat <- sort(abs(CorDat), decreasing=TRUE)
FundData <- FundData[,colnames(CorDat)]
# FundData
x2Tmp <- NULL
tmpCnms <- NULL
# for each original variable:
for ( iTmp in 2:ncol(FundData) ) {
# multiply it by itself and all other terms,
# excluding already generated pairwise combinations:
for ( jTmp in iTmp:ncol(FundData) ) {
x2Tmp <- cbind(x2Tmp,FundData[,iTmp]*FundData[,jTmp])
# maintain vector of column names for quadratic
# terms along the way:
tmpCnms <- c(tmpCnms,paste0("X",iTmp,"X",jTmp))
}
}
colnames(x2Tmp) <- tmpCnms
FundData <- data.frame(FundData, x2Tmp)
df2plot <- NULL
for ( iTmp in 2:ncol(FundData) ) {
lmTmp <- lm(FundData$contrib~.,FundData[,1:iTmp])
errTmp <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
df2plot <- rbind(df2plot,data.frame(nvars=iTmp-1,err=errTmp))
}
plot(df2plot,xlab="Number of variables",ylab="Regression error",main=paste(nrow(FundData),"observations"),ylim=c(min(df2plot[,"err"]),sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2))))
abline(h=sqrt(mean((FundData[,"contrib"]-mean(FundData[,"contrib"]))^2)),lty=2)
# 50 bootstrap iterations
errTrain <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
errTest <- matrix(NA,nrow=50,ncol=ncol(FundData)-1)
# vector to store the training error of each model
# fitted on all observations:
allTrainErr <- numeric()
# this loop tries different models: with 1, 2, 3, ... predictor variables
# (note that first predictor is the second column in
# the input data - the first column is the outcome "Y"):
for ( iTmp in 2:ncol(FundData) ) {
# fit model that inludes iTmp-1 first variables (in the order they occur
# in the columns of inpDat):
lmTmp <- lm(contrib~.,FundData[,1:iTmp])
# (use summary(lmTmp)$sigma if you want correction for the degrees of freedom)
# training error of the current model (iTmp-1 predictors) fitted on all data:
allTrainErr[iTmp-1] <- sqrt(mean((FundData[,"contrib"]-predict(lmTmp))^2))
# Now let's cross-validate the current model using bootstrap.
# Perform nBoot intependent bootstrapping resamplings to accumulate the statistics:
for ( iBoot in 1:50 ) {
# in each resampling iteration, generate a new bootstrapped sample
# (replace=TRUE is critical for bootstrap to work correctly!):
tmpBootIdx <- sample(nrow(FundData),nrow(FundData),replace=TRUE)
# now tmpBootIdx are the indexes of observations in the original data that were
# randomly selected (in this particular bootstrap iteration) to be placed into the training set.
# Now fit the current model on the bootstrap sample:
lmTmpBoot <- lm(contrib~.,FundData[tmpBootIdx,1:iTmp])
# calculate the MSE for the current bootstrap iteration
# (or use summary(lmTmpBoot)$sigma for degrees of freedom correction):
errTrain[iBoot,iTmp-1] <- sqrt(mean((FundData[tmpBootIdx,"contrib"]-predict(lmTmpBoot))^2))
# test error is calculated on the observations
# =not= in the bootstrap sample - thus "-tmpBootIdx"
errTest[iBoot,iTmp-1] <- sqrt(mean((FundData[-tmpBootIdx,"contrib"]-
predict(lmTmpBoot,newdata=FundData[-tmpBootIdx,1:iTmp]))^2))
}
}
# return results (bootstrap training errors, bootstrap test errors, and training errors
# claculated on the full dataset) as different slots in the list:
MyInpRes <- list(bootTrain=errTrain,bootTest=errTest,allTrain=allTrainErr)
plotBootRegrErrRes <- function(inpRes,inpPchClr=c(1,2,4),...) {
matplot(1:length(inpRes$allTrain),cbind(inpRes$allTrain,
colMeans(inpRes$bootTrain),
colMeans(inpRes$bootTest)
),
pch=inpPchClr,col=inpPchClr,lty=1,type="b",xlab="Number of predictors",ylab="Regression error",...)
legend("topright",c("train all","train boot","test boot"),
col=inpPchClr,text.col=inpPchClr,pch=inpPchClr,lty=1)
}
plotBootRegrErrRes(MyInpRes,main="3470 observations")
abline(h=sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2)),lty=2)
FundDataCopy
FundDataWithPred <- fundraising
FundDataWithPred <- fundraising
FundDataWithPred
FundDataWithPred <- FundDataWithPred[,-13]
FundDataWithPred <- FundDataWithPred[,-13]
FundDataWithPred <- fundraising
FundDataWithPred <- FundDataWithPred[,-13]
FundDataWithPred <- log(FundDataWithPred + 1)
FundDataWithPred
plotBootRegrErrRes(MyInpRes,main="3470 observations")
abline(h=sqrt(mean((mean(FundData[,"contrib"])-FundData[,"contrib"])^2)),lty=2)
prederror <- sqrt(mean((FundDataWithPred[,"contrib"])-FundDataWithPred[,"predcontr"])^2)
prederror
