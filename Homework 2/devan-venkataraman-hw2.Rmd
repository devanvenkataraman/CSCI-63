---
title: 'CSCI E-63C: Week 2 Problem Set'
author: 'Devan Venkataraman'
date: 6/26/20
output:
  html_document:
    toc: true
---

# Wireless Indoor Localization Data Set (30 points)

This dataset presents an example of classification problem (room identity) using continuous predictors derived from the strengths of several WiFi signals on a smartphone. More details about underlying data can be found in corresponding [dataset description](http://archive.ics.uci.edu/ml/datasets/Wireless+Indoor+Localization) at UCI ML website. To load data into R please use data file `wifi_localization.txt` available both at the course website and/or in UCI ML dataset repository.

Once the dataset in loaded into R, please name appropriately data set attributes (variables), determine the number of variables (explain which ones are predictors and which one is the outcome) and observations in the dataset (R functions such as `dim`, `nrow`, `ncol` could be useful for this), generate summary of the data using `summary` function in R and generate pairwise XY-scatterplots of each pair of continuous predictors, while indicating the outcome using colour and/or shape of the symbols (you may find it convenient to use `pairs` plotting function). Describe your observations and discuss which of the variables are more likely to be informative with respect to discriminating these rooms (this literally means: just by looking at the plots, for the lack of better methods that we have not developed just yet, which variables do you think will be more useful for letting us tell which room the smartphone is in).

Next, please comment on whether given the data at hand the problem of detecting room identity on the basis of the strength of the WiFi signal appears to be an easy or a hard one to solve. Try guessing, using your best intuition, what could be an error in predicting room identity in this dataset: 50%, 20%, 10%, 5%, 2%, less than that?  Later in the course we will work with this dataset again to actually develop such a classifier, and at that point you will get quantitative answer to this question. For now, what we are trying to achieve is to make you *think* about the data and to provide a (guesstimate) answer just from visual inspection of the scatterplots. Thus, there is no wrong answer at this point, just try your best, explain your (qualitative) reasoning, and make a note of your answer, so you can go back to it several weeks later.  

Finally, please reflect on potential usage of such a model (predicting room identity on the basis of WiFi signal strength) and discuss some of the limitations that the predictive performance of such a model may impose on its utility. Suppose that we can never achieve perfect identification (it's statistics after all), so we will end up with some finite error rate. For instance, if this model was integrated into a "smart home" setup that turns the light on or off depending on which room the smartphone is in, how useful would  be such model if its error rate was, say, 1%, 10% or 50%?  Can you think of alternative scenarios where this type of model could be used which would impose stricter or more lax requirements for its predictive performance?  Once again, the goal here is to prompt you to consider bigger picture aspects that would impact the utility of the model -- there is hardly right or wrong answer to this question, but please do present some kind of summary of your thoughts on this topic, even if in a couple of sentences.

``` {r WirelessIndoorLocalization1}
library(splus2R)
library(ggplot2)
library(GGally)
# read in the data
wifiData <- read.table("./wifi_localization.txt", header=FALSE, sep="\t")

# give columns names
i <- 1
for (i in 1:7) {
  names(wifiData)[i] <- sprintf("Signal %i", i)
}
names(wifiData)[8] <- "Room"
head(wifiData)

wifiData$Room <- as.factor(wifiData$Room)

# find number of vars and observations
dim(wifiData)

# give summary of the data
summary(wifiData)
```

**There are 8 variables in the data set. The first 7 are the wifi strengths, which are each predictor variables and continuous. The 8th variable is the room, which represents the outcome / decision variable and is categorical. There are 2000 observations in the data set.**

``` {r WirelessIndoorLocalization2}
# plot pairs
wifiData.pairs <- ggpairs(
 wifiData,
 mapping = ggplot2::aes(color = Room),
# upper = list(continuous = wrap("density", alpha = 0.5), combo = "box"),
 lower = list(continuous = wrap("points", alpha = 0.3,    size=0.1), 
              combo = wrap("dot", alpha = 0.4,            size=0.2) ),
 title = "Pairwise WifiData Scatterplots by Room")

wifiData.pairs
```

**Based on the pairwise plotting of predictor variables compared to the outcome of Room, it appears that variables that may be more informative in predicting the room are Wifi Signals 1, 4, 5, and possibly 3. Based on the boxplots generated by the categorical variable Room, each of these signals show relatively low variation for each room, based on thinner interquartile ranges. Less variation in each room reflects less "overlap", meaning that even with just knowledge of 1 signal we may be able to do a decent job of predicting the room. Now incorporating the pairwise plots, the relatively separated data in plots such as Signal 1 vs. 4 and 3 vs. 4 suggest that given a combination of 2 signals from those above, there would be an even higher chance of predicting the correct Room. Based on the dataset and visuals, I would guess there would be about 15% error in predicting room identity.**

**Finally, my first thought when considering implications of the dataset was geotracking. My school considered implementing trackers to take attendance when students entered their classroom, but if the predicting model resulted in 15% error as I guessed, there would be consequences in the utility of the model. If there were a more lenient setting, for example the model was used to determine whether people were inside a building of the 4 rooms vs outside, as long as the dataset could set a strength threshold that would suggest a person was inside vs. out, it may be less important that the exact room is predicted correctly.**


# Amount of Fund Raising Contributions (30 points)

This dataset presents an example of a regression problem -- predicting dollar amount of donors' contributions from a direct mail campaign based on their demographics and history of past contributions.  This dataset is a cleaned up subset of one of the datasets used in data mining competitions in the late 90s and it comes with the requirement of describing its source in rather broad (i.e. non-specific) terms if or when it is used for educational purposes.  To load data into R please use file `fund-raising.csv` available at the course website in Canvas.  More details about the data attributes can be found in corresponding file `fund-raising-notes.txt` also available from our course website in Canvas. 

Once the dataset in loaded into R, please determine the number of variables (explain which ones are predictors -- categorical vs. continuous -- and which one is the outcome) and observations in the dataset (R functions such as `dim`, `nrow`, `ncol` could be useful for this), generate summary of the data using `summary` function in R and generate pairwise XY-scatterplots of each pair of *continuous* attributes.

Describe your observations and discuss which attributes might be more useful for predicting the outcome as defined in the `fund-raising-notes.txt` dataset description. 

Try being creative: visualizing and discussing potential associations between each of individual (continuous) predictor variables and the continuous outcome is relatively straightforward. But this time around you cannot really use the outcome to stratify the points in the *pairwise* predictor-predictor scatterplots same way we did it in Problem 1: there we had just four possible values of the (categorical) outcome, but how many distinct values of the donor contribution do we have now? Do the plots make much sense and are they even interpretable if you use all those distinct values of contributed amount, as they are? Is there a way around this?

For **extra 5 points** generate boxplots for some of the continuous vs categorical predictors, rendering potential relationships between them.

``` {r FundraisingContributions}

# read in and setup
fundraising <- read.table("./fund-raising.csv", header=TRUE, sep=",")
fundraising$gender <- as.factor(fundraising$gender)

# find num of vars
dim(fundraising)
```
**There are 13 total variables in the dataset. The outcome variable is contrib, the donation amount per donor that is associated with the mailing campaign. The remaining 12 variables can be considered predictors. Of those 12 variables, 11 (gapmos, promocontr, mincontrib, ncontrib, maxcontrib, lastcontr, aavecontr, mailord, mindate, maxdate and age) can be considered "continuous". Although some of these variables may only take on discrete numerical values, the notion of order and an even interval suggests that we should analyze them as continuous. On the other hand, gender is considered categorical. There are 3,470 observations in the dataset.**

``` {r FundraisingContributions1}
# generate summary of the data
summary(fundraising)

# generate pairwise plots for all continuous variables
ggpairs(fundraising[,-ncol(fundraising)],
 mapping = ggplot2::aes(color = contrib),
 upper = list(continuous = wrap("density", alpha = 0.2), combo = "box"),
 lower = list(continuous = wrap("points", alpha = 0.1, size=0.04), 
              combo = wrap("dot", alpha = 0.4, size=0.1) ),
 title = "Pairwise Scatterplots of Fundraising Data")
```

**In this problem we cannot stratify pairwise plots via the outcome variable (contrib) because it is continuous. So, it is more difficult to estimate which predictor variables may be of greater influence to the outcome variable via the pairwise plots alone. That being said, by viewing the plots of each predictor variable against the outcome variable contrib and in context of the variable's meanings, it would suggest that the average contribution, last contribution, and max contribution would be decent predictors of the outcome variable. More specific analysis will be needed to support this hypothesis or suggest otherwise.**

``` {r FundraisingContributions2}
old.par <- par(mfrow=c(2,2),ps=16)

# plot each predictor variable against outcome var contrib
for (i in 1:(numCols(fundraising)-1)) {
  plot(fundraising[,i], fundraising$contrib, 
       xlab=names(fundraising)[i], 
       ylab="contrib",
       col="darkgreen",
       main=sprintf("contrib vs %s", names(fundraising)[i]))
}
```

**To start the analysis, I simply graphed the outcome variable contribut versus each of the continuous predictor variables. This gives us a better idea that variables such as last contribution, average contribution, and even age may be decent predictors of the outcome variable. However, a few outliers prevent the visual plots from providing convincing evidence, so I will perform numerical analysis on some of those predictor variables of interest.**

``` {r FundraisingContributions3}
bigcon <- fundraising$contrib>=75
olddonor <- fundraising$age>=40
agetable <- table(bigcon, olddonor)
agetable
# quantile of olddonor
(3184+22)/3470
# % of bigcons
22/numRows(fundraising)
```
**From the visual of contribution vs. age, it appeared that very few contributions were contributing to a skew of the data, and that perhaps there would be a takeaway with respect to age. To put this theory to test, I defined a large contribution as one that was over $75, to select only those largest data points. Then, I defined an old donor as one over 40 years old (~92nd quantile). A matrix of the two threshholds shows that (according to the training set) given that there is a large contribution, albeit only 0.6% of observations, it is certain that it will be from a donor at the 92nd quantile or above (>= 50 years old). Although this conclusion only applies to a small portion of the data, it may be an effective manner of categorizing those largest contributions.**

``` {r FundraisingContributions4}
for(i in 1:numCols(fundraising)-1) {
  print(cor(fundraising$contrib, fundraising[i]))
}
```

**Next, I calculated the correlation between contribution and all other continuous predictor variables. The results confirm that average contribution could be a good predictor of contribution, and that last contribution may be an even better predictor. In context of the meaning of these variables, these would make sense as good predictors, as we would expect a donor's contribution to be similar to his or her average / most recent contribution.**

``` {r FundraisingContributions5}

plot1 <- ggplot(fundraising, aes(y=ncontrib, group=gender)) + 
  ylim(0,50) +
  geom_boxplot(aes(fill=gender))
plot1

plot2 <- ggplot(fundraising, aes(y=age, group=gender)) +
  geom_boxplot(aes(fill=gender))
plot2

plot3 <- ggplot(fundraising, aes(y=promocontr, group=gender)) +
  geom_boxplot(aes(fill=gender))
plot3
```

**Above, I generated boxplots of 3 continuous variables stratified by gender. In the first plot of number of contributions, male and female donors had about the same median number of contributions. However, females had a slightly higher 3rd quartile, suggesting that a greater number of females donate more often than males. The second plot of age shows that the data is rather evenly distributed between males and females. Finally, a plot of the number of contributions to mailing campaigns suggests that females may be more responsive to the format of a mailing campaign, given the increase in disparity from males compared to the first ncontrib plot.**

# Tibbles (extra 5 points)

Fluency in R (as any other programming language) involves ability to look up, understand, and put to use as necessary new functionality that has not been explored before.  One of relatively recent additions to R are so-called tibbles that can be seen as ["modern take on data frames"](https://cran.r-project.org/web/packages/tibble/vignettes/tibble.html).  To earn extra points offered by this problem, please look up tibble use and constrast their behavior to that of conventional data frame using one of the datasets you have already created above.  To earn all points available your solution must include *more than one* example of substantive differences (same kind of difference illustrated by two datasets counts as *one example*).  Please also comment (briefly is fine) on why the use of tibbles may result in more robust code (or not, it's fine if you happen to find tibbles to be in fact clunkier and not resulting in cleaner code - but you have to argue your point, either way).

**Tibbles are a "modern" form of data frame that take the important functionalities from a traditional dataframe to make data manipulation as easy as possible. Tibbles are considered "lazy and surly", meaning they aren't capable of as much (such as changing names) and complain more often (will not allow for invalid variable calls). **
``` {r Tibbles}
library(tibble)
df <- data.frame(xvar=1:5, yvar=6:10)
df
df$xv

tib <- tibble(xvar=1:5, yvar=6:10)
tib
tib$xv
```

**The example above shows how tibbles do not perform partial matching. In order to access a variable in a tibble, the entirety of the name must be stated. While potentially preventing shortcuts, this feature may result in more readable code, as all calls are made explicitly and completely. **

``` {r Tibbles2}
myname <- (xvar=c("devan", "bhavani", "venkataraman"))
mydf <- data.frame(myname)
mydf
class(mydf$myname)

mytibble <- as_tibble(myname)
mytibble
class(mytibble$value)
```

**In the example above, I create a data frame based on a vector of my name. The data frame automatically converts the character column into a factor. Meanwhile, when I do the same with a tibble, the type remains a character. This could be helpful in cases such as this, where the set of characters has no statistical meaning, and should not be converted to factor.**

**I think code could be cleaner using tibbles primarily because they do not change variable type. In a dynamic typing language such as R, mistakes, confusion, and unexpected results can occur when typing is not made clear and consistent. With tibbles, actions such as subsetting can ensure that the user will get exactly what they expect, and can perhaps write more modular code.**