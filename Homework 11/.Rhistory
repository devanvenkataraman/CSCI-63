ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
summary(tune.out)
trainIdx <- smaple(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
head(trainIdx)
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
dim(trainIdx)
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
trainIdx
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
svmTrain <- svm(Loc~., data=wTrain, kernel="linear", cost=myCost, scale=FALSE)
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wTrain,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
print(summary(tune.out))
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
svmTrain <- svm(Loc~., data=wTrain, kernel="linear", cost=1, scale=FALSE)
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
print(summary(tune.out))
}
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
summary(tune.out)
tune
?tune
tune.out$cost
tune.out[,1]
tune.out
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
print(summary(tune.out))
tune.out
tune.out[1]
tune.out[1,1]
tune.out["cost"]
tune.out
class(tune.out)
mode(tune.out)
tune.out[1]
tune.out[[1]]
mode(tune.out[[1]])
tune.out$best.model
tune.out$best.tune()
tune.out$performance
tune.out$best.parameters
tune.out$best.parameters[1]
tune.out$best.parameters[1,1]
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
bestmod <- tune.out$best.model
ypred <- predict(bestmod, wTest)
}
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
bestmod <- tune.out$best.model
ypred <- predict(bestmod, wTest)
print(table(predict=ypred, truth=wTest$Loc))
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
bestmod <- tune.out$best.model
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable))
print(errorrate)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
bestmod <- tune.out$best.model
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
print(resultstable)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
print("10 tunings + predictions using bootstrapping")
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
print("10 tunings + predictions using bootstrapping")
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 5, 10, 20, 50,100)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
print("10 tunings + predictions using bootstrapping")
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
?randomForest
rf <- randomForest(Loc~., data=wifiLocDat)
rf
?randomForest
rf$confusion
rf$confusion
diag(rf$confusion)
(1-sum(diag(rf$confusion)))
sum(diag(rf$confusion))/sum(rf$confusion)
1-sum(diag(rf$confusion))/sum(rf$confusion)
rf <- randomForest(Loc~., data=wifiLocDat)
rf$confusion
1-sum(diag(rf$confusion))/sum(rf$confusion)
?tune.knn
tune.knn(Loc~., data=wifiLocDat)
?knn
?tune.knn
tune.knn(x=wTrain, wTest)
tune.knn(x=wTrain, y=wTest)
tune.knn(x=wTrain)
tune.knn(x=wTrain, y=wTest, k=1:5)
head(wifiLocDat)
tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=1:5)
optmodel <- tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=1:5)
optmodel$best.parameters[1,1]
dim(wifiLocDat)
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=c(1, 5, 10, 20, 50, 100, 500))
optknn <- tune.out$best.parameters[1,1]
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
bestmodel <- tune.out$best.model
print(optknn)
ypred <- predict(bestmoded, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wifiLocDat[,-8], y=wifiLocDat[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
bestmodel <- tune.out$best.model
print(optknn)
ypred <- predict(bestmodel, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
tune.out$best.model
knn
?knn
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
print(optknn)
knnpred <- knn(wTrain, wTest, k=optknn)
resultstable <- table(predict=knnpred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
print(optknn)
knnpred <- knn(wTrain, wTest, wTest$Loc, k=optknn)
resultstable <- table(predict=knnpred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
library(randomForest)
library(MASS)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
classTrain <- factor(classTrain > 0)
``` {r subproblem1pt1}
library(randomForest)
library(MASS)
library(class)
library(ggplot2)
knitr::opts_chunk$set(echo = TRUE)
# Generate the dataset, repeat 3 times
for (nObs in c(25, 100, 500)) {
# How many predictors are associated with outcome:
nClassVars <- 2
# How many predictors are not:
nNoiseVars <- 3
# To modulate average difference between two classes' predictor values:
deltaClass <- 1
# Simulate training and test datasets with an interaction
# between attribute levels associated with the outcome:
xyzTrain <- matrix(rnorm(nObs*(nClassVars+nNoiseVars)),nrow=nObs,ncol=nClassVars+nNoiseVars)
xyzTest <- matrix(rnorm(10000*(nClassVars+nNoiseVars)),nrow=10000,ncol=nClassVars+nNoiseVars)
classTrain <- 1
classTest <- 1
for ( iTmp in 1:nClassVars ) {
deltaTrain <- sample(deltaClass*c(-1,1),nObs,replace=TRUE)
xyzTrain[,iTmp] <- xyzTrain[,iTmp] + deltaTrain
classTrain <- classTrain * deltaTrain
deltaTest <- sample(deltaClass*c(-1,1),10000,replace=TRUE)
xyzTest[,iTmp] <- xyzTest[,iTmp] + deltaTest
classTest <- classTest * deltaTest
}
classTrain <- factor(classTrain > 0)
classTrain
print(paste("Number of observations: ", nObs))
rfRes <- randomForest(xyzTrain,classTrain)
rfTmpTbl <- table(classTest,predict(rfRes,newdata=xyzTest))
ldaRes <- lda(xyzTrain,classTrain)
ldaTmpTbl <- table(classTest,predict(ldaRes,newdata=xyzTest)$class)
dfTmp <- NULL
for ( kTmp in seq(1,nObs/2,length.out = 20) ) {
knnRes <- knn(xyzTrain,xyzTest,classTrain,k=kTmp)
tmpTbl <- table(classTest,knnRes)
dfTmp <- rbind(dfTmp,data.frame(err=1-sum(diag(tmpTbl))/sum(tmpTbl),k=kTmp))
}
print(ggplot(dfTmp,aes(x=k,y=err))+geom_point()+scale_x_log10()+geom_hline(aes(yintercept = err,colour=type),data=data.frame(type=c("LDA","RF"),err=c(1-sum(diag(ldaTmpTbl))/sum(ldaTmpTbl),1-sum(diag(rfTmpTbl))/sum(rfTmpTbl))))+ggtitle("KNN error rate"))
}
classTrain <- factor(classTrain > 0)
classTrain
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
optknn <- tune.out$best.parameters[1,1]
print(optknn)
mode(wTest$Loc)
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
print(optknn)
knnpred <- knn(wTrain, wTest, cl=factor(wTest$Loc), k=optknn)
resultstable <- table(predict=knnpred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
factor <- factor(wTest$Loc)
factor
length(factor)
knnpred <- knn(wTrain, wTest, cl=factor(wTest$Loc), k=optknn)
length(wTrain)
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
trainIdx
knnpred <- knn(wTrain, wTest, cl=factor(wTrain$Loc), k=optknn)
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
print(optknn)
knnpred <- knn(wTrain, wTest, cl=factor(wTrain$Loc), k=optknn)
resultstable <- table(predict=knnpred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
head(wifiLocDat)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+Wifi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
}
head(wifiLocDat)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
}
plot(svmRes, data=wifiLocDat)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
mode(wifiLocDat$Loc)
library(ISLR)
library(e1071)
library(randomForest)
library(class)
library(ggplot2)
library(GGally)
knitr::opts_chunk$set(echo = TRUE)
wifiLocDat <- read.table("wifi_localization_copy.txt", sep="\t", header=TRUE)
colnames(wifiLocDat) <- c(paste0("WiFi",1:7),"Loc")
head(wifiLocDat)
wifiLocDat[,"Loc"] <- as.factor(wifiLocDat[,"Loc"])
for (myCost in c(0.001, 1, 1000, 1000000)) {
svmfit <- svm(Loc~., data=wifiLocDat, kernel="linear", cost=myCost, scale=FALSE)
print(summary(svmfit))
}
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.001, 0.01, 0.1, 1,5,10,50,100)))
summary(tune.out)
print("10 tunings + predictions using bootstrapping")
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
rf <- randomForest(Loc~., data=wifiLocDat)
rf$confusion
1-sum(diag(rf$confusion))/sum(rf$confusion)
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out <- tune.knn(x=wTrain[,-8], y=wTrain[,8], k=c(1, 5, 10, 20, 50, 100))
optknn <- tune.out$best.parameters[1,1]
print(optknn)
knnpred <- knn(wTrain, wTest, cl=factor(wTrain$Loc), k=optknn)
resultstable <- table(predict=knnpred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
mode(wifiLocDat$Loc)
wifiLocDat[,"Loc"] <- as.factor(wifiLocDat[,"Loc"])
mode(wifiLocDat$Loc)
# wifiLocDat[,"Loc"] <- as.factor(wifiLocDat[,"Loc"])
class(wifiLocDat$Loc)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
# wifiLocDat[,"Loc"] <- as.factor(wifiLocDat[,"Loc"])
class(wifiLocDat$Loc)
# wifiLocDat[,"Loc"] <- as.factor(wifiLocDat[,"Loc"])
class(wifiLocDat$Loc)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDat, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
wifiLocDatShrunk <- wifiLocDat[,c(1,2,8)]
head(wifiLocDatShrunk)
wifiLocDatShrunk <- wifiLocDat[,c(1,2,8)]
head(wifiLocDatShrunk)
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDatShrunk, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
``` {r subproblem4pt1}
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDatShrunk, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDat)
}
for ( myGamma in c(0.5, 5, 50)) {
svmRes <- svm(Loc~WiFi1+WiFi2, data = wifiLocDatShrunk, kernel="radial", cost=10, gamma=myGamma)
plot(svmRes, data=wifiLocDatShrunk)
}
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100), gamma=c(0.1, 1, 5, 10, 50)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
?tune
errorrates <- vector()
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100), gamma=c(0.1, 1, 5, 10, 50)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters[1,1])
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
print(errorrate)
}
errorrates <- vector()
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100), gamma=c(0.1, 1, 5, 10, 50)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters)
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
errorrates[i] <- errorrate
print(errorrate)
}
errorrates <- vector()
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100), gamma=c(0.1, 1, 5, 10, 50)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters)
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
errorrates[iTry] <- errorrate
print(errorrate)
}
errorrates <- vector()
for (iTry in 1:10) {
trainIdx <- sample(nrow(wifiLocDat), nrow(wifiLocDat), replace=TRUE)
wTrain <- wifiLocDat[trainIdx,]
wTest <- wifiLocDat[-trainIdx,]
tune.out=tune(svm,Loc~.,data=wifiLocDat,kernel="linear",
ranges=list(cost=c(0.1, 1, 2, 5, 10, 20, 50,100), gamma=c(0.1, 1, 5, 10, 50)))
bestmod <- tune.out$best.model
print(tune.out$best.parameters)
ypred <- predict(bestmod, wTest)
resultstable <- table(predict=ypred, truth=wTest$Loc)
errorrate <- (1-sum(diag(resultstable)/sum(resultstable)))
errorrates[iTry] <- errorrate
}
plot(errorrates)
