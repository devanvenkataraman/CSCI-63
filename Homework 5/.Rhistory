for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove prediction variable
FundData <- fundraising[,-14]
head(FundData)
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
head(FundData)
dim(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 14 because gender categorical attribute can take on two values
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=14)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove prediction variable
FundData <- fundraising[,-14]
head(FundData)
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
head(FundData)
dim(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 14 because gender categorical attribute can take on two values
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=14)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(2,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}s
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove prediction variable
FundData <- fundraising[,-14]
head(FundData)
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
head(FundData)
dim(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 14 because gender categorical attribute can take on two values
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=14)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(2,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
head(fundraising)
# Remove prediction variable
FundData <- fundraising[,-14]
head(FundData)
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
head(FundData)
dim(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 15 because gender categorical attribute can take on three distinct values
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=15)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(1,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
algaeRaw <- read.table ("coil.analysis.data", header=F, sep =",", row.names =NULL, na.strings ="XXXXXXX")
colnames (algaeRaw)= c("season","size","velocity",paste0("C",1:8),paste0("AG",1:7))
algaeRaw[1:3,]
# remove cases with undefined values and three outliers:
algae <- na.omit(algaeRaw)
algae <- algae[algae[,"C4"]<max(algae[,"C4"],na.rm=TRUE)&algae[,"C3"]<max(algae[,"C3"],na.rm=TRUE)&algae[,"AG4"]<max(algae[,"AG4"],na.rm=TRUE),]
# log-transform selected attributes:
for ( iCol in 1:8 ) {
if ( iCol > 2 ) {
algae[,paste0("C",iCol)] <- log(algae[,paste0("C",iCol)])
}
if ( iCol < 8 ) {
algae[,paste0("AG",iCol)] <- log(1+algae[,paste0("AG",iCol)])
}
}
# we'll use AG2 as an outcome here:
algaeAG2 <- algae[,!colnames(algae)%in%paste0("AG",c(1,3:7))]
dim(algaeAG2)
head(algaeAG2)
pairs(algaeAG2[,-(1:3)])
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 15 because three categorical attributes are represented by dummy variables:
rsRes <- regsubsets(AG2~.,algaeAG2,method=myMthd,nvmax=15)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(2,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}
par(old.par)
predict.regsubsets <- function (object, newdata, id, ...){
form=as.formula(object$call [[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names (coefi)
mat[,xvars] %*% coefi
}
dfTmp <- NULL
whichSum <- array(0,dim=c(15,16,4),
dimnames=list(NULL,colnames(model.matrix(AG2~.,algaeAG2)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(algaeAG2)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(AG2~.,algaeAG2[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:15 ) {
# make predictions:
testPred <- predict(rsTrain,algaeAG2[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-algaeAG2[!bTrain,"AG2"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
old.par <- par(mfrow=c(2,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in dimnames(whichSum)[[3]] ) {
tmpWhich <- whichSum[,,myMthd] / nTries
image(1:nrow(tmpWhich),1:ncol(tmpWhich),tmpWhich,
xlab="N(vars)",ylab="",xaxt="n",yaxt="n",main=myMthd,
breaks=c(-0.1,0.1,0.25,0.5,0.75,0.9,1.1),
col=c("white","gray90","gray75","gray50","gray25","gray10"))
axis(1,1:nrow(tmpWhich),rownames(tmpWhich))
axis(2,1:ncol(tmpWhich),colnames(tmpWhich),las=2)
}
par(old.par)
# -1 to get rid of intercept that glmnet knows to include:
x <- model.matrix(AG2~.,algaeAG2)[,-1]
head(algaeAG2)
# notice how it created dummy variables for categorical attributes
head(x)
y <- algaeAG2[,"AG2"]
ridgeRes <- glmnet(x,y,alpha=0)
plot(ridgeRes)
cvRidgeRes <- cv.glmnet(x,y,alpha=0)
plot(cvRidgeRes)
cvRidgeRes$lambda.min
cvRidgeRes$lambda.1se
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.min)
predict(ridgeRes,type="coefficients",s=cvRidgeRes$lambda.1se)
# and with lambda's other than default:
cvRidgeRes <- cv.glmnet(x,y,alpha=0,lambda=10^((-80:80)/20))
plot(cvRidgeRes)
ridgeResScaled <- glmnet(scale(x),y,alpha=0)
plot(ridgeResScaled)
cvRidgeResScaled <- cv.glmnet(scale(x),y,alpha=0)
plot(cvRidgeResScaled)
predict(ridgeResScaled,type="coefficients",s=cvRidgeResScaled$lambda.1se)
lassoRes <- glmnet(x,y,alpha=1)
plot(lassoRes)
cvLassoRes <- cv.glmnet(x,y,alpha=1)
plot(cvLassoRes)
# With other than default levels of lambda:
cvLassoRes <- cv.glmnet(x,y,alpha=1,lambda=10^((-120:0)/20))
plot(cvLassoRes)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.1se)
predict(lassoRes,type="coefficients",s=cvLassoRes$lambda.min)
lassoResScaled <- glmnet(scale(x),y,alpha=1)
plot(lassoResScaled)
cvLassoResScaled <- cv.glmnet(scale(x),y,alpha=1)
plot(cvLassoResScaled)
predict(lassoResScaled,type="coefficients",s=cvLassoResScaled$lambda.1se)
lassoCoefCnt <- 0
lassoMSE <- NULL
for ( iTry in 1:30 ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(x)))
cvLassoTrain <- cv.glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrain <- glmnet(x[bTrain,],y[bTrain],alpha=1)
lassoTrainCoef <- predict(lassoTrain,type="coefficients",s=cvLassoTrain$lambda.1se)
lassoCoefCnt <- lassoCoefCnt + (lassoTrainCoef[-1,1]!=0)
lassoTestPred <- predict(lassoTrain,newx=x[!bTrain,],s=cvLassoTrain$lambda.1se)
lassoMSE <- c(lassoMSE,mean((lassoTestPred-y[!bTrain])^2))
}
mean(lassoMSE)
lassoCoefCnt
dfTmp <- NULL
whichSum <- array(0,dim=c(15,16,4),
dimnames=list(NULL,colnames(model.matrix(AG2~.,algaeAG2)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(algaeAG2)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(AG2~.,algaeAG2[bTrain,],nvmax=15,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:15 ) {
# make predictions:
testPred <- predict(rsTrain,algaeAG2[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-algaeAG2[!bTrain,"AG2"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
summary(rsTrain)$which
print(summary(rsTrain)$which)
console.log(summary(rsTrain)$which)
summary(rsTrain)$which
dim(FundData)
head(FundData)
(FundData)
dim(FundData)
head(FundData)
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
# Remove prediction variable
FundData <- fundraising[,-14]
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
dim(FundData)
head(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 13 because 12 cont. vars + gender categorical attribute takes on one of three distinct values, represented via 2 dummy variables
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=13)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(1,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}
# Define a predict function for regsubsets class
predict.regsubsets <- function (object, newdata, id, ...){
form=as.formula(object$call [[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names (coefi)
mat[,xvars] %*% coefi
}
dfTmp <- NULL
# 13 models for 13 total variables, 14 columns of which bc/ intercept, 4 methods
whichSum <- array(0,dim=c(13,14,4),
dimnames=list(NULL,colnames(model.matrix(contrib~.,FundData)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(FundData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(contrib~.,FundData[bTrain,],nvmax=13,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:13 ) {
# make predictions:
testPred <- predict(rsTrain,FundData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-FundData[!bTrain,"AG2"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
library(ISLR)
library(leaps)
library(ggplot2)
library(glmnet)
knitr::opts_chunk$set(echo = TRUE)
fundraising <- read.table("./fund-raising-with-predictions.csv", header=TRUE, sep=",")
# Remove prediction variable
FundData <- fundraising[,-14]
# Log-transform data
FundData[,-13] <- log(FundData[,-13] + 1)
dim(FundData)
head(FundData)
summaryMetrics <- NULL
whichAll <- list()
for ( myMthd in c("exhaustive", "backward", "forward", "seqrep") ) {
# 13 because 12 cont. vars + gender categorical attribute takes on one of three distinct values, represented via 2 dummy variables
rsRes <- regsubsets(contrib~.,FundData,method=myMthd,nvmax=13)
summRes <- summary(rsRes)
whichAll[[myMthd]] <- summRes$which
for ( metricName in c("rsq","rss","adjr2","cp","bic") ) {
summaryMetrics <- rbind(summaryMetrics,
data.frame(method=myMthd,metric=metricName,
nvars=1:length(summRes[[metricName]]),
value=summRes[[metricName]]))
}
}
ggplot(summaryMetrics,aes(x=nvars,y=value,shape=method,colour=method)) + geom_path() + geom_point() + facet_wrap(~metric,scales="free") +   theme(legend.position="top")+theme_bw()
old.par <- par(mfrow=c(1,2),ps=16,mar=c(5,7,2,1))
for ( myMthd in names(whichAll) ) {
image(1:nrow(whichAll[[myMthd]]),
1:ncol(whichAll[[myMthd]]),
whichAll[[myMthd]],xlab="N(vars)",ylab="",
xaxt="n",yaxt="n",breaks=c(-0.5,0.5,1.5),
col=c("white","gray"),main=myMthd)
axis(1,1:nrow(whichAll[[myMthd]]),rownames(whichAll[[myMthd]]))
axis(2,1:ncol(whichAll[[myMthd]]),colnames(whichAll[[myMthd]]),las=2)
}
# Define a predict function for regsubsets class
predict.regsubsets <- function (object, newdata, id, ...){
form=as.formula(object$call [[2]])
mat=model.matrix(form,newdata)
coefi=coef(object,id=id)
xvars=names (coefi)
mat[,xvars] %*% coefi
}
dfTmp <- NULL
# 13 models for 13 total variables, 14 columns of which bc/ intercept, 4 methods
whichSum <- array(0,dim=c(13,14,4),
dimnames=list(NULL,colnames(model.matrix(contrib~.,FundData)),
c("exhaustive", "backward", "forward", "seqrep")))
# Split data into training and test 30 times:
nTries <- 30
for ( iTry in 1:nTries ) {
bTrain <- sample(rep(c(TRUE,FALSE),length.out=nrow(FundData)))
# Try each method available in regsubsets
# to select the best model of each size:
for ( jSelect in c("exhaustive", "backward", "forward", "seqrep") ) {
rsTrain <- regsubsets(contrib~.,FundData[bTrain,],nvmax=13,method=jSelect)
# Add up variable selections:
whichSum[,,jSelect] <- whichSum[,,jSelect] + summary(rsTrain)$which
summary(rsTrain)$which
# Calculate test error for each set of variables
# using predict.regsubsets implemented above:
for ( kVarSet in 1:13 ) {
# make predictions:
testPred <- predict(rsTrain,FundData[!bTrain,],id=kVarSet)
# calculate MSE:
mseTest <- mean((testPred-FundData[!bTrain,"contrib"])^2)
# add to data.frame for future plotting:
dfTmp <- rbind(dfTmp,data.frame(sim=iTry,sel=jSelect,vars=kVarSet,
mse=c(mseTest,summary(rsTrain)$rss[kVarSet]/sum(bTrain)),trainTest=c("test","train")))
}
}
}
# plot MSEs by training/test, number of
# variables and selection method:
ggplot(dfTmp,aes(x=factor(vars),y=mse,colour=sel)) + geom_boxplot()+facet_wrap(~trainTest)+theme_bw()
head(fundraising)
# log original dataset for accurate error comparisons
fundrasing2 <- log(fundraising[,-13] + 1)
head(fundraising2)
# log original dataset for accurate error comparisons
fundrasing2 <- log(fundraising[,-13] + 1)
head(fundraising2)
# log original dataset for accurate error comparisons
fundraising2 <- log(fundraising[,-13] + 1)
head(fundraising2)
comp.mse <- mean((fundraising2[,"contrib"]-fundraising2["predcontr"])^2)
comp.mse
fundraising2[,"contrib"]
fundraising2[,"precontr"]
fundraising2[,"predcontr"]
comp.mse <- mean((fundraising2[,"contrib"]-fundraising2["predcontr"])^2)
comp.mse <- mean((fundraising2[,"contrib"]-fundraising2[,"predcontr"])^2)
comp.mse
